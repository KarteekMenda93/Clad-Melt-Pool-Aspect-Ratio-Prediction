{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --q requests_html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQUrQrNd1Z58",
        "outputId": "4791b73f-df7a-49c8-beb6-b7c1f505eddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Fxpfo-r1Ld1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import requests\n",
        "from requests_html import HTMLSession, AsyncHTMLSession\n",
        "from bs4 import BeautifulSoup as bs\n",
        "import asyncio\n",
        "if asyncio.get_event_loop().is_running():\n",
        "  import nest_asyncio\n",
        "  nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change this to specifiy the data URL and the  number of pages you want to scrape\n",
        "\n",
        "session = AsyncHTMLSession()\n",
        "headers={'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15'}\n",
        "\n",
        "page_rows = []\n",
        "page_num = 1\n",
        "res = 0\n",
        "total = 1\n",
        "headers_found = False\n",
        "\n",
        "while res != total and page_num <= 5:\n",
        "  url = f'http://senvol.com/5_material-results/?appSession=0LTD9N6NY50DFEC28SO9N86TP49WFI6R6GEO4242743X1UP61EW017ASO6LS75SQX9CX2NW0G6Z6G8S456523E2RT203784AYQ578JEI6N0Q1I1MF957ZES52XGY3K38&PageID=2&PrevPageID=&cpipage={page_num}&CPISortType=&CPIorderBy=&appSession=26D32R65NSJT4F758HXOR2LE407P1479FX808Z5288IX77J2J5XK0RJX1Q99KFV05V5FF5K5Z1PHFF754130M6P3SQZ7CU1KUE5J5O367I9OG0YOL8WD1HH6D2D3F802&PageID=2&PrevPageID=&cpipage=2&CPISortType=&CPIorderBy='\n",
        "  page_num += 1\n",
        "\n",
        "  r = await session.get(url,headers=headers)\n",
        "  await r.html.arender(timeout=20, retries=3)\n",
        "  resp = r.html.raw_html\n",
        "  soup = bs(resp, 'html.parser')\n",
        "\n",
        "  table = soup.find('table', {'id':re.compile(r'cbTable_')})\n",
        "  rows = table.find_all('tr', {'id':re.compile(r'DataRow')})\n",
        "  for row in rows:\n",
        "    page_rows.append([item.text for item in row.find_all('td')])\n",
        "    if not headers_found:\n",
        "      header_raw = table.find('tr', class_=re.compile(r'cbResultSetTableHeader_'))\n",
        "      header = [label.text for label in header_raw.find_all('th', class_=re.compile(r'cbResultSetHeaderCell'))]\n",
        "      headers_found = True\n",
        "\n",
        "  record_text = soup.find('td', class_=re.compile(r'cbResultSetRecordMessage_')).text\n",
        "  nums = re.findall(r'\\d+', record_text)\n",
        "  res = nums[1]\n",
        "  total = nums[2]\n",
        "\n",
        "  print(f'page {page_num-1}: results {res} of {total} scraped')\n",
        "\n",
        "senvol_df = pd.DataFrame(page_rows, columns=header)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z2GO6wI1YZ-",
        "outputId": "cb22e755-e23f-406c-f660-91331e884613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[INFO] Starting Chromium download.\n",
            "INFO:pyppeteer.chromium_downloader:Starting Chromium download.\n",
            "100%|██████████| 183M/183M [00:01<00:00, 127Mb/s]\n",
            "[INFO] Beginning extraction\n",
            "INFO:pyppeteer.chromium_downloader:Beginning extraction\n",
            "[INFO] Chromium extracted to: /root/.local/share/pyppeteer/local-chromium/1181205\n",
            "INFO:pyppeteer.chromium_downloader:Chromium extracted to: /root/.local/share/pyppeteer/local-chromium/1181205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page 1: results 25 of 4236 scraped\n",
            "page 2: results 25 of 4236 scraped\n",
            "page 3: results 25 of 4236 scraped\n",
            "page 4: results 25 of 4236 scraped\n",
            "page 5: results 25 of 4236 scraped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "senvol_df.head()"
      ],
      "metadata": {
        "id": "e-GLNZaC1lx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "senvol_df.to_csv('./AM_MasterData.csv')"
      ],
      "metadata": {
        "id": "-g7iuwn01ojw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}